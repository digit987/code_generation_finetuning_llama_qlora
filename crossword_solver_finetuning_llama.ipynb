{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2776951,"sourceType":"datasetVersion","datasetId":1695035},{"sourceId":9410394,"sourceType":"datasetVersion","datasetId":5714300}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install accelerate peft bitsandbytes transformers trl wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-16T11:48:22.705091Z","iopub.execute_input":"2024-09-16T11:48:22.705382Z","iopub.status.idle":"2024-09-16T11:48:43.588708Z","shell.execute_reply.started":"2024-09-16T11:48:22.705349Z","shell.execute_reply":"2024-09-16T11:48:43.587447Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nfrom datasets import Dataset, load_dataset\nimport pandas as pd\nfrom peft import LoraConfig\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nimport torch\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:27.303819Z","iopub.execute_input":"2024-09-16T11:49:27.304212Z","iopub.status.idle":"2024-09-16T11:49:27.309571Z","shell.execute_reply.started":"2024-09-16T11:49:27.304177Z","shell.execute_reply":"2024-09-16T11:49:27.308450Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Model from Hugging Face hub\nbase_model = \"NousResearch/Meta-Llama-3-8B\"\n\n# Fine-tuned model\nnew_model = \"Meta-Llama-3-8B-Crossword\"","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:31.049342Z","iopub.execute_input":"2024-09-16T11:49:31.049772Z","iopub.status.idle":"2024-09-16T11:49:31.054286Z","shell.execute_reply.started":"2024-09-16T11:49:31.049735Z","shell.execute_reply":"2024-09-16T11:49:31.053365Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/crossword/nytcrosswords.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:33.201883Z","iopub.execute_input":"2024-09-16T11:49:33.202607Z","iopub.status.idle":"2024-09-16T11:49:34.397068Z","shell.execute_reply.started":"2024-09-16T11:49:33.202563Z","shell.execute_reply":"2024-09-16T11:49:34.396113Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:36.351875Z","iopub.execute_input":"2024-09-16T11:49:36.352790Z","iopub.status.idle":"2024-09-16T11:49:37.546886Z","shell.execute_reply.started":"2024-09-16T11:49:36.352744Z","shell.execute_reply":"2024-09-16T11:49:37.545871Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"             Date    Word     Clue\ncount      781573  781539   781573\nunique      10207   63313   493935\ntop     5/16/1999     ERA  Jai ___\nfreq          181     634      122","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Word</th>\n      <th>Clue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>781573</td>\n      <td>781539</td>\n      <td>781573</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>10207</td>\n      <td>63313</td>\n      <td>493935</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>5/16/1999</td>\n      <td>ERA</td>\n      <td>Jai ___</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>181</td>\n      <td>634</td>\n      <td>122</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Keeping only unique rows based on 'Clue' column\ndf_unique = df.drop_duplicates(subset=['Clue'])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:44.233688Z","iopub.execute_input":"2024-09-16T11:49:44.234089Z","iopub.status.idle":"2024-09-16T11:49:44.413261Z","shell.execute_reply.started":"2024-09-16T11:49:44.234052Z","shell.execute_reply":"2024-09-16T11:49:44.412322Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_unique.describe()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:46.577229Z","iopub.execute_input":"2024-09-16T11:49:46.577784Z","iopub.status.idle":"2024-09-16T11:49:47.403548Z","shell.execute_reply.started":"2024-09-16T11:49:46.577744Z","shell.execute_reply":"2024-09-16T11:49:47.402583Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"             Date    Word             Clue\ncount      493935  493917           493935\nunique      10207   61391           493935\ntop     10/3/2021     ERA  King's superior\nfreq          138     356                1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Word</th>\n      <th>Clue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>493935</td>\n      <td>493917</td>\n      <td>493935</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>10207</td>\n      <td>61391</td>\n      <td>493935</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>10/3/2021</td>\n      <td>ERA</td>\n      <td>King's superior</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>138</td>\n      <td>356</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Shuffling the DataFrame\ndf_unique = df_unique.sample(frac=1).reset_index(drop=True)\n\n# Calculating number of samples for each split\n#total_samples = len(df_unique)\ntotal_samples = 5000 # Currently keeping it to 5000 due to resource constraints\ntrain_size = int(0.7 * total_samples)  # 70% for training\nvalidation_size = int(0.15 * total_samples)   # 15% for validation\ntest_size = total_samples - train_size - validation_size  # Remaining for test\n\n# Splitting into training, validation, and test sets\ntrain_df = df_unique.iloc[:train_size]\nvalidation_df = df_unique.iloc[train_size:train_size + validation_size]\ntest_df = df_unique.iloc[train_size + validation_size:]","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:50.206268Z","iopub.execute_input":"2024-09-16T11:49:50.206650Z","iopub.status.idle":"2024-09-16T11:49:50.356098Z","shell.execute_reply.started":"2024-09-16T11:49:50.206616Z","shell.execute_reply":"2024-09-16T11:49:50.355250Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Converting pandas DataFrames to datasets\ntrain_dataset = Dataset.from_pandas(train_df)\nvalidation_dataset = Dataset.from_pandas(validation_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:52.685440Z","iopub.execute_input":"2024-09-16T11:49:52.686349Z","iopub.status.idle":"2024-09-16T11:49:53.023130Z","shell.execute_reply.started":"2024-09-16T11:49:52.686309Z","shell.execute_reply":"2024-09-16T11:49:53.022303Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Defining a function to merge intent and snippet into a single column\ndef merge_columns(example):\n    clue = example[\"Clue\"]\n    word = example[\"Word\"]\n    merged_text = f\"<s> [INST]{clue} [/INST] {word} </s>\"\n    return {\"text\": merged_text}  # Return a dictionary with the merged text\n\n# Apply the merge function to each split of the dataset\ntrain_dataset = train_dataset.map(merge_columns)\nvalidation_dataset = validation_dataset.map(merge_columns)\ntest_dataset = test_dataset.map(merge_columns)\n\n# Convert dictionaries to strings\ntrain_dataset = [example[\"text\"] for example in train_dataset]\nvalidation_dataset = [example[\"text\"] for example in validation_dataset]\ntest_dataset = [example[\"text\"] for example in test_dataset]\n\n# Show the number of samples in each split\nprint(\"Number of samples in train split:\", len(train_dataset))\nprint(\"Number of samples in validation split:\", len(validation_dataset))\nprint(\"Number of samples in test split:\", len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:49:56.608512Z","iopub.execute_input":"2024-09-16T11:49:56.609414Z","iopub.status.idle":"2024-09-16T11:51:00.769129Z","shell.execute_reply.started":"2024-09-16T11:49:56.609374Z","shell.execute_reply":"2024-09-16T11:51:00.768150Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48ad719bf2a04a0591e9eeb5d1308d22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f65dbd0bf9534df484bc5d382338f699"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/489685 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf7c37767af444f82b9cf3825bf8e89"}},"metadata":{}},{"name":"stdout","text":"Number of samples in train split: 3500\nNumber of samples in validation split: 750\nNumber of samples in test split: 489685\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert the list of strings to a dataset object\ntrain_dataset = Dataset.from_dict({\"text\": train_dataset})\nvalidation_dataset = Dataset.from_dict({\"text\": validation_dataset})\ntest_dataset = Dataset.from_dict({\"text\": test_dataset})","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:51:09.286132Z","iopub.execute_input":"2024-09-16T11:51:09.287065Z","iopub.status.idle":"2024-09-16T11:51:09.587866Z","shell.execute_reply.started":"2024-09-16T11:51:09.287022Z","shell.execute_reply":"2024-09-16T11:51:09.586584Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset[0:5]","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:51:13.064847Z","iopub.execute_input":"2024-09-16T11:51:13.065744Z","iopub.status.idle":"2024-09-16T11:51:13.072457Z","shell.execute_reply.started":"2024-09-16T11:51:13.065704Z","shell.execute_reply":"2024-09-16T11:51:13.071448Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'text': ['<s> [INST]Heroine of Wagner\\'s \"The Flying Dutchman\" [/INST] SENTA </s>',\n  '<s> [INST]Distributed [/INST] SOWN </s>',\n  '<s> [INST]\"Super Hits\" company [/INST] KTEL </s>',\n  '<s> [INST]\"Rotten School\" series author [/INST] STINE </s>',\n  '<s> [INST]Watson, Willard and Woodhouse [/INST] EMMAS </s>']}"},"metadata":{}}]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:51:16.998407Z","iopub.execute_input":"2024-09-16T11:51:16.998809Z","iopub.status.idle":"2024-09-16T11:51:17.005126Z","shell.execute_reply.started":"2024-09-16T11:51:16.998773Z","shell.execute_reply":"2024-09-16T11:51:17.004210Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=quant_config,\n    device_map={\"\": 0}\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:51:20.777614Z","iopub.execute_input":"2024-09-16T11:51:20.778409Z","iopub.status.idle":"2024-09-16T11:55:57.823899Z","shell.execute_reply.started":"2024-09-16T11:51:20.778367Z","shell.execute_reply":"2024-09-16T11:55:57.822839Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76ad9d01f714497082af9d0967cc5f18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58d3fdedbb0643759e07492cc48e4c22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ded17be65df48939cb95b62e8cdcfc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c273ac098494dd8878ff9554aa3e98f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3af5c28d72240f1a443367523449ada"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb791f79a38042ef8d02681b6f701fc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"441d4e7ae88b45ff81d04b12106eb560"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78837bc1ee744961baac1cf72f9c7f2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86475afa66034219826c5c4522fc864f"}},"metadata":{}}]},{"cell_type":"code","source":"# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:56:07.996938Z","iopub.execute_input":"2024-09-16T11:56:07.997813Z","iopub.status.idle":"2024-09-16T11:56:09.874778Z","shell.execute_reply.started":"2024-09-16T11:56:07.997773Z","shell.execute_reply":"2024-09-16T11:56:09.873789Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02b040750cf642b3a9fa271286161e84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ffff040c8f7428b970d49e02112ecda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcc3c6385ed240739583a1fb2b4042e2"}},"metadata":{}}]},{"cell_type":"code","source":"# Load LoRA configuration\npeft_args = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:56:15.235486Z","iopub.execute_input":"2024-09-16T11:56:15.235894Z","iopub.status.idle":"2024-09-16T11:56:15.240878Z","shell.execute_reply.started":"2024-09-16T11:56:15.235857Z","shell.execute_reply":"2024-09-16T11:56:15.239859Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"training_params = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_32bit\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=False,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:56:20.610622Z","iopub.execute_input":"2024-09-16T11:56:20.611383Z","iopub.status.idle":"2024-09-16T11:56:20.646763Z","shell.execute_reply.started":"2024-09-16T11:56:20.611340Z","shell.execute_reply":"2024-09-16T11:56:20.645715Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    peft_config=peft_args,\n    dataset_text_field=\"text\",\n    max_seq_length=None,\n    tokenizer=tokenizer,\n    args=training_params,\n    packing=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:56:30.564235Z","iopub.execute_input":"2024-09-16T11:56:30.565120Z","iopub.status.idle":"2024-09-16T11:56:31.656716Z","shell.execute_reply.started":"2024-09-16T11:56:30.565078Z","shell.execute_reply":"2024-09-16T11:56:31.655765Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0fb5c79ec474725bbfd79b11b4bb3bc"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T11:56:51.033928Z","iopub.execute_input":"2024-09-16T11:56:51.034737Z","iopub.status.idle":"2024-09-16T12:37:03.897024Z","shell.execute_reply.started":"2024-09-16T11:56:51.034696Z","shell.execute_reply":"2024-09-16T12:37:03.896072Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [875/875 40:08, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>3.725500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.352600</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>2.227100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.047900</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.703300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.601500</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>1.587000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.576000</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>1.607000</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.530900</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>1.590100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.594000</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>1.557700</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.534100</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>1.522100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.576800</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>1.531100</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.518400</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>1.493100</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.578500</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>1.569500</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.590600</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>1.529400</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.507200</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>1.547600</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.534400</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>1.474500</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.551700</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>1.577500</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.516600</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>1.526100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.591200</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>1.508300</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.577800</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>1.495000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=875, training_loss=1.6729201093401227, metrics={'train_runtime': 2412.1869, 'train_samples_per_second': 1.451, 'train_steps_per_second': 0.363, 'total_flos': 3121172853202944.0, 'train_loss': 1.6729201093401227, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save trained model\ntrainer.model.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T13:20:27.715403Z","iopub.execute_input":"2024-09-16T13:20:27.715828Z","iopub.status.idle":"2024-09-16T13:20:28.197183Z","shell.execute_reply.started":"2024-09-16T13:20:27.715786Z","shell.execute_reply":"2024-09-16T13:20:28.196372Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer.tokenizer.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T13:21:39.423177Z","iopub.execute_input":"2024-09-16T13:21:39.423600Z","iopub.status.idle":"2024-09-16T13:21:39.665115Z","shell.execute_reply.started":"2024-09-16T13:21:39.423557Z","shell.execute_reply":"2024-09-16T13:21:39.664152Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"('Meta-Llama-3-8B-Crossword/tokenizer_config.json',\n 'Meta-Llama-3-8B-Crossword/special_tokens_map.json',\n 'Meta-Llama-3-8B-Crossword/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n\n# Load the fine-tuned model and tokenizer from the local directory\nnew_model = AutoModelForCausalLM.from_pretrained(\"Meta-Llama-3-8B-Crossword\")\ntokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Meta-Llama-3-8B\", trust_remote_code=True)\n\n# Ignore warnings\nimport logging\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\n\n# Run text generation pipeline with our fine-tuned model\nprompt = \"<s> <INST> Capital of USA </INST>\"\npipe = pipeline(task=\"text-generation\", model=new_model, tokenizer=tokenizer, max_length=200)\nresult = pipe(prompt)\nprint(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T13:54:56.338989Z","iopub.execute_input":"2024-09-16T13:54:56.339826Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec133d205f7a42ab85bcd632d14d9869"}},"metadata":{}}]}]}